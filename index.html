<!DOCTYPE html>
<!--
 - File              : index.html
 - Author            : Marcos Horro <marcos.horro@udc.gal>
 - Last Modified Date: Mar 18 Set 2018 15:46:32 CEST
-->
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Ben Saunders">
    <meta name="author" content="Ben Saunders">

    <title>Ben Saunders</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/custom.css" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
  </head>

  <body>
    <!-- header -->
    <header>
      <!-- Fixed navbar -->
      <nav class="navbar navbar-expand-md fixed-top bg-dark bg-udc">
        <div class="container">
          <a class="navbar-brand" href="https://www.surrey.ac.uk/">
            <img src="img/university-of-surrey.svg" width="200" height="30" alt="UDC">
          </a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
          <i class="fas fa-bars"></i></button>
    		  <div class="collapse navbar-collapse" id="navbarNavDropdown">
            <ul class="navbar-nav">
              <li class="nav-item">
                <a class="nav-link" href="#about">About<span class="sr-only">(current)</span></a>
                <li class="nav-item">
              </li>
                <a class="nav-link" href="#news">News</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#research">Research</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#pubs">Publications</a>
              </li>
            </ul>
          </div>
        </div>
    	</nav>
    </header>

    <!-- Begin page content -->
    <main role="main" class="container">
    <div class="row">
      <div class="col-4 mx-auto d-block">
        <div class="row mt-5 mx-auto d-block text-center">
          <img src="img/Personal_Photo.jpeg" class="img-fluid rounded-circle mb-3" alt="Profile picture">
          <h4>Ben Saunders</h4>
          <p class="lead">PhD Candidate (University of Surrey)</p>
          <p class="font-weight-light">
           Centre for Vision,Speech and Signal 
		  Processing (CVSSP)</p>
        </div>
        <hr>
        <div class="row mx-auto d-block">
        <p class="lead text-center "><a href="mailto:b.saunders@surrey.ac.uk"><i class="far fa-envelope"></i></a> b.saunders@surrey.ac.uk</p>
        <ul class="social-icons text-center">
          	<li><a class="scholar" href="https://scholar.google.co.uk/citations?user=DQfrcJkAAAAJ&hl=en" title="Scholar">Scholar</a></li>
          	<li><a class="linkedin" href="https://www.linkedin.com/in/ben-saunders-4b5b24aa/" title="Linkedin">LinkedIn</a></li>
          	<li><a class="researchgate" href="https://www.researchgate.net/profile/Ben-Saunders-9" title="ResearchGate">ResearchGate</a></li>
          	<li><a class="twitter" href="https://twitter.com/BenMSaunders" title="Twitter">Twitter</a></li>
        </ul>
        <hr>
      </div>
      </div>
     
     
       <div class="col-8">
        <section id="about" class="mt-5">
          <h3 class="display-5">About</h3><hr>
          <p class="font-weight-light"> 
         I am a 2nd year PhD Student at the <a href="https://www.surrey.ac.uk/centre-vision-speech-signal-processing">Centre for Vision, Speech and Signal Processing (CVSSP)</a> researching <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560664.pdf"> Sign Language Production</a>, under the supervision of 
		<a href="http://personal.ee.surrey.ac.uk/Personal/R.Bowden/">Prof. Richard Bowden</a> and <a href="https://www.cihancamgoz.com/">Necati Cihan Camgoz</a>. I received my Master's degree with distinction in Artificial Intelligence from <a href="https://www.qmul.ac.uk/">Queen Mary University</a>, having achieved first class honours in my Bachelor's from <a href="https://www.lse.ac.uk/">London School of Economics</a>.
	<br><br>
	I grew up in <a href="https://www.youtube.com/watch?v=FGd97AIfPJw">Poole, UK</a> (obvs the best beach on earth) and spent some time in Moscow as a child (with my family, not alone). After graduating from LSE, I worked at <a href="https://www.accenture.com/gb-en">Accenture</a> as a Robotics Technology Analyst (sounds cooler than it was), where I fell in love with coding, robotics and particularly AI. I pursued this interest during my Master's, combining my interest in accessibility through technology and computer vision for my dissertation on Depth Estimation for the Visually Impaired. 
	<br><br>
  	Pursuing a PhD in Machine Learning was the next logical step, with a focus on the <a href="https://cvssp.org/projects/extol/"> neural production of sign languages </a> as the perfect topic. My primary research focus has been on how computer vision and natural language processing can be used to translate spoken language sentences into photo-realistic sign language sequences, aka Sign Language Production.
         <br><br>
	  Feel free to contact me to chat about my research or potential collaborations.
		</p>
        </section>
     
        <section id="news" class="mt-5">
          <h3 class="display-5">News</h3><hr>
          <p class="font-weight-light"> 
                       <ul class="clist">
            <li> <span class="badge badge-secondary">May. '21</span> 1 paper accepted to an International Journal of Computer Vision (<a href="https://link.springer.com/content/pdf/10.1007/s11263-021-01457-9.pdf">IJCV</a>) Special Issue on Human pose, Motion, Activities and Shape in 3D
          </li> 
		</ul>		       
		<ul class="clist">
            <li> <span class="badge badge-secondary">Nov. '20</span> I successfully defended my 1 year PhD Confirmation
          </li>        
         </ul>
            <ul class="clist">
            <li> <span class="badge badge-secondary">Sep. '20</span> 1 paper accepted to the British Machine Vision Conference (<a href="https://www.bmvc2020-conference.com/assets/papers/0223.pdf">BMVC 2020</a>)
          </li> 
          </ul>
            <ul class="clist">
            <li> <span class="badge badge-secondary">Aug. '20</span> 1 paper accepted to the European Conference on Computer Vision (<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560664.pdf">ECCV 2020</a>)
          </li> 
	  </ul>
            <ul class="clist">
            <li> <span class="badge badge-secondary">Aug. '19</span> I graduated with a Distinction from my Artificial Intelligence Master's at Queen Mary University
          </li> 
         
        </section>
       <section id="research" class="mt-5">
          <h3 class="display-5">Research</h3><hr>
          <p class="font-weight-light"> 
           My long-term research goal is to develop cutting-edge technology designed specifically for the disabled, using computer vision and natural language processing. I believe that all people can and should benefit from the current AI technologoical advances. 
           <br><br>
	I am particularly interested in Computational Sign Language research, with a focus on the translation from spoken language sequences to continuous sign language sequences. In addition, I want to move the field of Sign Langauge Production away from a skeletal representation towards photo-realistic sign language videos.
	<br><br>
           My current research focus can be summarised as:
           <ul>
            <li>Neural Sign Language Production (<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560664.pdf">ECCV'20</a>, <a href="https://www.bmvc2020-conference.com/assets/papers/0223.pdf">BMVC'20</a>, <a href="https://link.springer.com/content/pdf/10.1007/s11263-021-01457-9.pdf">IJCV'21</a>)</li>
            <li>Photo-Realistic Sign Language Video Generation (<a href="https://arxiv.org/pdf/2011.09846.pdf">ArXiv</a>)</li>
          </ul>
         </p>
        </section>
               <section id="pubs" class="mt-5">
          <h3 class="display-5">Publications</h3>
          <hr>
           <h4>2021</h4>     
	
         <ul class="clist">
           <li> 
            <a href="https://arxiv.org/abs/2105.02351"> Content4All Open Research Sign Language Translation Datasets </a>
          <br>
          Necati Cihan Camgoz, <u>Ben Saunders</u>, Guillaume Rochette, Marco Giovanelli, Giacomo Inches, Robin Nachtrab-Ribback and Richard Bowden
           <br>
            <i>ArXiv preprint 2105.02351</i>
            <br>
         </ul>
		       
           <ul class="clist">
           <li> 
            <a href="https://link.springer.com/content/pdf/10.1007/s11263-021-01457-9.pdf"> Continuous 3D Multi-Channel Sign Language Production via Progressive Transformers and Mixture Density Networks </a>
          <br>
          <u>Ben Saunders</u>, Necati Cihan Camgoz and Richard Bowden
           <br>
            <i>JInternational Journal of Computer Vision (IJCV) Special Issue on Human Pose, Motion, Activities and Shape in 3D </i>
            <br>
         </ul>
		       
	<ul class="clist">
           <li> 
            SeeHear: Signer Diarisation and a new Dataset
          <br>
          Samuel Albanie, Gül Varol, Liliane Momeni, Triantafyllos Afouras, Andrew Brown, Chuhan Zhang, Ernesto Coto, Necati Cihan Camgöz, <u>Ben Saunders</u>, Neil Fox, Abhishek Dutta, Richard Bowden, Bencie Woll  and Andrew Zisserman
           <br>
            <i>International Conference on Acoustics, Speech, and Signal Processing (ICASSP) (To Appear) </i>
            <br>
         </ul>
            

          <h4>2020</h4>
	
       <ul class="clist">
           <li> 
            <a href="https://arxiv.org/pdf/2011.09846.pdf"> Everybody Sign Now: Translating Spoken Language to Photo Realistic Sign Language Video </a>
          <br>
          <u>Ben Saunders</u>, Necati Cihan Camgoz and Richard Bowden
           <br>
            <i>arXiv preprint arXiv:2011.09846</i>
            <br>
         </ul>
		       
      <ul class="clist">
           <li> 
            <a href="https://www.bmvc2020-conference.com/assets/papers/0223.pdf"> Adversarial Training for Multi-Channel Sign Language Production </a>
          <br>
          <u>Ben Saunders</u>, Necati Cihan Camgoz and Richard Bowden
           <br>
            <i>Proceedings of the British Machine Vision Conference (BMVC) </i>
            <br>
         </ul>
		       
       <ul class="clist">
           <li> 
            <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560664.pdf"> Progressive Transformers for End-to-End Sign Language Production </a>
          <br>
          <u>Ben Saunders</u>, Necati Cihan Camgoz and Richard Bowden
           <br>
            <i>Proceedings of the European Conference on Computer Vision (ECCV) </i>
            <br>
           <a href="https://github.com/BenSaunders27/ProgressiveTransformersSLP"> Code </a>
         </ul>
		       
      </div>
    </div>
    </main>

    <footer class="footer">
      <div class="container">
        <span class="text-muted"><i class="fas fa-university"></i> Centre for Vision, Speech and Sign Processing (CVSSP), University of Surrey</span>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script>window.jQuery || document.write('<script src="js/jquery-slim.min.js"><\/script>')</script>
    <script src="js/popper.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/bibtex.js"></script>
<script type="text/javascript">
 var init = function() {
   bibtexify("#bibtex", "pubTable", {});
 };
 if (window.addEventListener) {
   window.addEventListener('load', init, false);
 } else if (window.attachEvent) {
   window.attachEvent('onload', init);
 }
</script>
<script>
jQuery("#pubTable").on("click", "a", function(e) {
  var $n = jQuery(this),
      text = $n.text().toUpperCase();
  if (text === "X") { return; }
  try {
    _gaq.push(['_trackEvent', "PublicationAction", text]);
} catch(err){ }
  if ($n.attr("href") !== "#") {
    setTimeout(function() {
      document.location.href = $n.attr("href");
    }, 100);
    return false;
  }
});
</script>
  </body>
</html>
